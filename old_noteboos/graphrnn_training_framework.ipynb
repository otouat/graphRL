{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Comparative experiments over GraphRNN, GRAN and GraphOpt\n",
    "Ousmane TOUAT\n",
    "\n",
    "## Purpose\n",
    "Investigating on those deep graph generators methods over small-words graph, in order to design a capable RL-based generator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "### Libraries import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#Include local libraries\n",
    "import sys, os\n",
    "from synthethicDataset.generate_graphs import *\n",
    "from baselineModels.GraphRNN.train import *\n",
    "from baselineModels.GraphRNN.model import *\n",
    "from baselineModels.GraphRNN.data import *\n",
    "from config.experiment_config import *\n",
    "from time import strftime, gmtime\n",
    "import scipy.misc\n",
    "from tensorboard_logger import configure, log_value\n",
    "from random import shuffle\n",
    "import random\n",
    "import pickle\n",
    "import shutil"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset initialization and creation\n",
    "We will generate graphs using stocasthic model such as Erdos Renyi or Barabasi Albert"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 0\n",
      "File name prefix GraphRNN_MLP_erdos_4_128_\n",
      "graph_validate_len 143.45\n",
      "graph_test_len 150.5\n",
      "total graph num: 100, training set: 80\n",
      "max number node: 199\n",
      "max/min number edge: 1973; 481\n",
      "max previous node: 173\n",
      "train and test graphs saved at:  ./baselineModels/GraphRNN/ModelData/graphs/GraphRNN_MLP_erdos_4_128_test_0.dat\n"
     ]
    }
   ],
   "source": [
    "args = Args()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(args.device)\n",
    "print('CUDA', args.device)\n",
    "print('File name prefix', args.fname)\n",
    "# check if necessary directories exist\n",
    "if not os.path.isdir(args.model_save_path):\n",
    "    os.makedirs(args.model_save_path)\n",
    "if not os.path.isdir(args.graph_save_path):\n",
    "    os.makedirs(args.graph_save_path)\n",
    "if not os.path.isdir(args.figure_save_path):\n",
    "    os.makedirs(args.figure_save_path)\n",
    "if not os.path.isdir(args.timing_save_path):\n",
    "    os.makedirs(args.timing_save_path)\n",
    "if not os.path.isdir(args.figure_prediction_save_path):\n",
    "    os.makedirs(args.figure_prediction_save_path)\n",
    "if not os.path.isdir(args.nll_save_path):\n",
    "    os.makedirs(args.nll_save_path)\n",
    "\n",
    "time = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "# logging.basicConfig(filename='logs/train' + time + '.log', level=logging.DEBUG)\n",
    "if args.clean_tensorboard:\n",
    "    if os.path.isdir(args.dir_input + \"tensorboard\"):\n",
    "        shutil.rmtree(args.dir_input + \"tensorboard\")\n",
    "configure(args.dir_input + \"/tensorboard/run\", flush_secs=5)\n",
    "\n",
    "graphs = generate(args)\n",
    "\n",
    "# split datasets\n",
    "random.seed(123)\n",
    "shuffle(graphs)\n",
    "graphs_len = len(graphs)\n",
    "graphs_test = graphs[int(0.8 * graphs_len):]\n",
    "graphs_train = graphs[0:int(0.8 * graphs_len)]\n",
    "graphs_validate = graphs[0:int(0.2 * graphs_len)]\n",
    "\n",
    "graph_validate_len = 0\n",
    "for graph in graphs_validate:\n",
    "    graph_validate_len += graph.number_of_nodes()\n",
    "graph_validate_len /= len(graphs_validate)\n",
    "print('graph_validate_len', graph_validate_len)\n",
    "\n",
    "graph_test_len = 0\n",
    "for graph in graphs_test:\n",
    "    graph_test_len += graph.number_of_nodes()\n",
    "graph_test_len /= len(graphs_test)\n",
    "print('graph_test_len', graph_test_len)\n",
    "\n",
    "args.max_num_node = max([graphs[i].number_of_nodes() for i in range(len(graphs))])\n",
    "max_num_edge = max([graphs[i].number_of_edges() for i in range(len(graphs))])\n",
    "min_num_edge = min([graphs[i].number_of_edges() for i in range(len(graphs))])\n",
    "\n",
    "# args.max_num_node = 2000\n",
    "# show graphs statistics\n",
    "print('total graph num: {}, training set: {}'.format(len(graphs), len(graphs_train)))\n",
    "print('max number node: {}'.format(args.max_num_node))\n",
    "print('max/min number edge: {}; {}'.format(max_num_edge, min_num_edge))\n",
    "print('max previous node: {}'.format(args.max_prev_node))\n",
    "\n",
    "# save ground truth graphs\n",
    "## To get train and test set, after loading you need to manually slice\n",
    "save_graph_list(graphs, args.graph_save_path + args.fname_train + '0.dat')\n",
    "save_graph_list(graphs, args.graph_save_path + args.fname_test + '0.dat')\n",
    "print('train and test graphs saved at: ', args.graph_save_path + args.fname_test + '0.dat')\n",
    "\n",
    "### dataset initialization\n",
    "dataset = Graph_to_sequence(graphs_train, max_prev_node=args.max_prev_node,\n",
    "                            max_num_node=args.max_num_node)\n",
    "sample_strategy = torch.utils.data.sampler.WeightedRandomSampler([1.0 / len(dataset) for i in range(len(dataset))],\n",
    "                                                                 num_samples=args.batch_size * args.batch_ratio,\n",
    "                                                                 replacement=True)\n",
    "dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, num_workers=args.num_workers,\n",
    "                                             sampler=sample_strategy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialisation of the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ousmane\\PycharmProjects\\graphRL\\baselineModels\\GraphRNN\\model.py:45: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(param, 0.25)\n"
     ]
    }
   ],
   "source": [
    "# All necessary arguments are defined in args.py\n",
    "args.max_prev_node = dataset.max_prev_node\n",
    "\n",
    "### model initialization\n",
    "if 'GraphRNN_MLP' in args.note:\n",
    "        node_level_rnn = RNN(input_size=args.max_prev_node, embedding_size=args.embedding_size_rnn,\n",
    "                        hidden_size=args.hidden_size_rnn, num_layers=args.num_layers, has_input=True,\n",
    "                        has_output=False).cuda()\n",
    "        edge_level_rnn = MLP_plain(h_size=args.hidden_size_rnn, embedding_size=args.embedding_size_output, y_size=args.max_prev_node).cuda()\n",
    "else:\n",
    "    node_level_rnn = RNN(input_size=args.max_prev_node, embedding_size=args.embedding_size_rnn,\n",
    "                         hidden_size=args.hidden_size_rnn, num_layers=args.num_layers, has_input=True,\n",
    "                         has_output=True, output_size=args.hidden_size_rnn_output).cuda()\n",
    "    edge_level_rnn = RNN(input_size=1, embedding_size=args.embedding_size_rnn_output,\n",
    "                         hidden_size=args.hidden_size_rnn_output, num_layers=args.num_layers, has_input=True,\n",
    "                         has_output=True, output_size=1).cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\graphRL\\lib\\site-packages\\torch\\nn\\functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-0382f0afd281>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m### start training\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataset_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnode_level_rnn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0medge_level_rnn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\graphRL\\baselineModels\\GraphRNN\\train.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(args, dataset_train, rnn, output)\u001B[0m\n\u001B[0;32m     45\u001B[0m             train_mlp_epoch(epoch, args, rnn, output, dataset_train,\n\u001B[0;32m     46\u001B[0m                             \u001B[0moptimizer_rnn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer_output\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 47\u001B[1;33m                             scheduler_rnn, scheduler_output)\n\u001B[0m\u001B[0;32m     48\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     49\u001B[0m             train_rnn_epoch(epoch, args, rnn, output, dataset_train,\n",
      "\u001B[1;32m~\\PycharmProjects\\graphRL\\baselineModels\\GraphRNN\\train.py\u001B[0m in \u001B[0;36mtrain_mlp_epoch\u001B[1;34m(epoch, args, rnn, output, data_loader, optimizer_rnn, optimizer_output, scheduler_rnn, scheduler_output)\u001B[0m\n\u001B[0;32m    313\u001B[0m     \u001B[0moutput\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    314\u001B[0m     \u001B[0mloss_sum\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 315\u001B[1;33m     \u001B[1;32mfor\u001B[0m \u001B[0mbatch_idx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_loader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    316\u001B[0m         \u001B[0mrnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    317\u001B[0m         \u001B[0moutput\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda3\\envs\\graphRL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    515\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    516\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 517\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    518\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    519\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda3\\envs\\graphRL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    555\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    556\u001B[0m         \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 557\u001B[1;33m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    558\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    559\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda3\\envs\\graphRL\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda3\\envs\\graphRL\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\graphRL\\baselineModels\\GraphRNN\\data.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[1;31m# then do bfs in the permuted G\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m         \u001B[0mstart_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0madj_copy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 52\u001B[1;33m         \u001B[0mx_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbfs_seq\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mG\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstart_idx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     53\u001B[0m         \u001B[0madj_copy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0madj_copy\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mix_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_idx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_idx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     54\u001B[0m         \u001B[0madj_encoded\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mencode_adj\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0madj_copy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_prev_node\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax_prev_node\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\graphRL\\baselineModels\\GraphRNN\\data.py\u001B[0m in \u001B[0;36mbfs_seq\u001B[1;34m(G, start_id)\u001B[0m\n\u001B[0;32m     97\u001B[0m     \u001B[1;32mwhile\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     98\u001B[0m         \u001B[0mnext\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 99\u001B[1;33m         \u001B[1;32mwhile\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    100\u001B[0m             \u001B[0mcurrent\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstart\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    101\u001B[0m             \u001B[0mneighbor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdictionary\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcurrent\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "### start training\n",
    "train(args, dataset_loader, node_level_rnn, edge_level_rnn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generated_graphs = test_rnn_epoch(0, args, node_level_rnn, edge_level_rnn, 50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nx.draw(generated_graphs[5])\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}