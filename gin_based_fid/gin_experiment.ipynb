{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# GIN Experiment\n",
    "This notebook will implement the evaluation pipeline with the FID calculation using the GIN"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from util import load_data, load_synth_data, separate_data\n",
    "from models.graphcnn import GraphCNN\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "def train(iters_per_epoch, batch_size, model, device, train_graphs, optimizer, epoch):\n",
    "    model.train()\n",
    "\n",
    "    total_iters = iters_per_epoch\n",
    "    pbar = tqdm(range(total_iters), unit='batch')\n",
    "\n",
    "    loss_accum = 0\n",
    "    for pos in pbar:\n",
    "        selected_idx = np.random.permutation(len(train_graphs))[:batch_size]\n",
    "\n",
    "        batch_graph = [train_graphs[idx] for idx in selected_idx]\n",
    "        output = model(batch_graph)\n",
    "\n",
    "        labels = torch.LongTensor([graph.label for graph in batch_graph]).to(device)\n",
    "\n",
    "        #compute loss\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        #backprop\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        loss = loss.detach().cpu().numpy()\n",
    "        loss_accum += loss\n",
    "\n",
    "        #report\n",
    "        pbar.set_description('epoch: %d' % (epoch))\n",
    "\n",
    "    average_loss = loss_accum/total_iters\n",
    "    print(\"loss training: %f\" % (average_loss))\n",
    "\n",
    "    return average_loss\n",
    "\n",
    "###pass data to model with minibatch during testing to avoid memory overflow (does not perform backpropagation)\n",
    "def pass_data_iteratively(model, graphs, minibatch_size = 64):\n",
    "    model.eval()\n",
    "    output = []\n",
    "    idx = np.arange(len(graphs))\n",
    "    for i in range(0, len(graphs), minibatch_size):\n",
    "        sampled_idx = idx[i:i+minibatch_size]\n",
    "        if len(sampled_idx) == 0:\n",
    "            continue\n",
    "        output.append(model([graphs[j] for j in sampled_idx]).detach())\n",
    "    return torch.cat(output, 0)\n",
    "\n",
    "def test(model, device, train_graphs, test_graphs, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    output = pass_data_iteratively(model, train_graphs)\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "    labels = torch.LongTensor([graph.label for graph in train_graphs]).to(device)\n",
    "    correct = pred.eq(labels.view_as(pred)).sum().cpu().item()\n",
    "    acc_train = correct / float(len(train_graphs))\n",
    "\n",
    "    output = pass_data_iteratively(model, test_graphs)\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "    labels = torch.LongTensor([graph.label for graph in test_graphs]).to(device)\n",
    "    correct = pred.eq(labels.view_as(pred)).sum().cpu().item()\n",
    "    acc_test = correct / float(len(test_graphs))\n",
    "\n",
    "    print(\"accuracy train: %f test: %f\" % (acc_train, acc_test))\n",
    "\n",
    "    return acc_train, acc_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataset = None\n",
    "device = 0\n",
    "batch_size = 32\n",
    "iters_per_epoch = 50\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "seed = 0\n",
    "fold_idx = 0\n",
    "num_layers = 5\n",
    "num_mlp_layers = 2\n",
    "hidden_dim = 64\n",
    "final_dropout = 0.5\n",
    "graph_pooling_type = \"sum\"\n",
    "neighbor_pooling_type = \"sum\"\n",
    "learn_eps = False\n",
    "degree_as_tag = True\n",
    "filename = \"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "# classes: 5\n",
      "# maximum node tag: 30\n",
      "# data: 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\graphRL\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "epoch: 1: 100%|██████████| 50/50 [00:14<00:00,  3.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 14.682701\n",
      "accuracy train: 0.974667 test: 0.968000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2:   6%|▌         | 3/50 [00:00<00:01, 25.08batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2: 100%|██████████| 50/50 [00:02<00:00, 21.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 1.818198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 3:   6%|▌         | 3/50 [00:00<00:02, 23.14batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.992889 test: 0.992000\n",
      "\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 3: 100%|██████████| 50/50 [00:02<00:00, 24.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 3.453346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 4:   6%|▌         | 3/50 [00:00<00:01, 27.60batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.957333 test: 0.952000\n",
      "\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 4: 100%|██████████| 50/50 [00:02<00:00, 21.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 1.573039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 5:   6%|▌         | 3/50 [00:00<00:01, 25.71batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.997778 test: 1.000000\n",
      "\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 5: 100%|██████████| 50/50 [00:01<00:00, 25.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.936425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 6:   6%|▌         | 3/50 [00:00<00:01, 27.60batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.988444 test: 0.992000\n",
      "\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 6: 100%|██████████| 50/50 [00:02<00:00, 21.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.998864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 7:   6%|▌         | 3/50 [00:00<00:02, 23.32batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.997333 test: 0.996000\n",
      "\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 7: 100%|██████████| 50/50 [00:02<00:00, 22.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.612225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 8:   6%|▌         | 3/50 [00:00<00:01, 26.57batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.996000 test: 1.000000\n",
      "\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 8: 100%|██████████| 50/50 [00:02<00:00, 21.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.359400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 9:   6%|▌         | 3/50 [00:00<00:01, 26.16batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999111 test: 0.996000\n",
      "\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 9: 100%|██████████| 50/50 [00:01<00:00, 25.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.256408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 10:   6%|▌         | 3/50 [00:00<00:01, 25.59batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 1.000000 test: 1.000000\n",
      "\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 10: 100%|██████████| 50/50 [00:02<00:00, 21.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.167052\n",
      "accuracy train: 0.993333 test: 0.992000\n",
      "\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#set up seeds and gpu device\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "device = torch.device(\"cuda:\" + str(device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "if dataset != None :\n",
    "    graphs, num_classes = load_data(dataset, degree_as_tag)\n",
    "else :\n",
    "    graphs, num_classes = load_synth_data(True)\n",
    "num_classes\n",
    "##10-fold cross validation. Conduct an experiment on the fold specified by args.fold_idx.\n",
    "train_graphs, test_graphs = separate_data(graphs, seed, fold_idx)\n",
    "\n",
    "model = GraphCNN(num_layers, num_mlp_layers, train_graphs[0].node_features.shape[1], hidden_dim, num_classes, final_dropout, learn_eps, graph_pooling_type, neighbor_pooling_type, device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_loss = train(iters_per_epoch,batch_size,model, device, train_graphs, optimizer, epoch)\n",
    "    acc_train, acc_test = test( model, device, train_graphs, test_graphs, epoch)\n",
    "\n",
    "    if not filename == \"\":\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(\"%f %f %f\" % (avg_loss, acc_train, acc_test))\n",
    "            f.write(\"\\n\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(model.eps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "output = pass_data_iteratively(model, graphs)\n",
    "##Get mu and cov of given graph SV2Graph batch\n",
    "embed_graphs = model.get_graph_embed_sum(graphs)\n",
    "a=embed_graphs.cpu().detach().numpy()\n",
    "mu = np.mean(a, axis = 0)\n",
    "cov = np.cov(a, rowvar = False)\n",
    "\n",
    "## Coming from https://github.com/mseitzer/pytorch-fid\n",
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    \"\"\"Numpy implementation of the Frechet Distance.\n",
    "    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n",
    "    and X_2 ~ N(mu_2, C_2) is\n",
    "            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n",
    "    Stable version by Dougal J. Sutherland.\n",
    "    Params:\n",
    "    -- mu1   : Numpy array containing the activations of a layer of the\n",
    "               inception net (like returned by the function 'get_predictions')\n",
    "               for generated samples.\n",
    "    -- mu2   : The sample mean over activations, precalculated on an\n",
    "               representative data set.\n",
    "    -- sigma1: The covariance matrix over activations for generated samples.\n",
    "    -- sigma2: The covariance matrix over activations, precalculated on an\n",
    "               representative data set.\n",
    "    Returns:\n",
    "    --   : The Frechet Distance.\n",
    "    \"\"\"\n",
    "\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "\n",
    "    assert mu1.shape == mu2.shape, \\\n",
    "        'Training and test mean vectors have different lengths'\n",
    "    assert sigma1.shape == sigma2.shape, \\\n",
    "        'Training and test covariances have different dimensions'\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "\n",
    "    # Product might be almost singular\n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        msg = ('fid calculation produces singular product; '\n",
    "               'adding %s to diagonal of cov estimates') % eps\n",
    "        print(msg)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "\n",
    "    # Numerical error might give slight imaginary component\n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError('Imaginary component {}'.format(m))\n",
    "        covmean = covmean.real\n",
    "\n",
    "    tr_covmean = np.trace(covmean)\n",
    "\n",
    "    return (diff.dot(diff) + np.trace(sigma1)\n",
    "            + np.trace(sigma2) - 2 * tr_covmean)\n",
    "\n",
    "fid=calculate_frechet_distance(mu,cov,mu,cov)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-d45cbc365cae>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'matplotlib'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'inline'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mseaborn\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0msns\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m \u001B[0msns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_style\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'darkgrid'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[0msns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_palette\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'muted'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "def fashion_scatter(x, colors):\n",
    "    # choose a color palette with seaborn.\n",
    "    num_classes = len(np.unique(colors))+1\n",
    "    palette = np.array(sns.color_palette(\"hls\", num_classes))\n",
    "\n",
    "    # create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40, c=palette[colors.astype(np.int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # add the labels for each digit corresponding to the label\n",
    "    txts = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "\n",
    "        # Position of each label at median of data points.\n",
    "\n",
    "        xtext, ytext = np.median(x[colors == i, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, str(i), fontsize=24)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "\n",
    "    return f, ax, sc, txts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X=output\n",
    "y = np.array([g.label for g in graphs])\n",
    "############################################################\n",
    "from sklearn.manifold import TSNE\n",
    "import time\n",
    "time_start = time.time()\n",
    "\n",
    "fashion_tsne = TSNE(random_state=0).fit_transform(X)\n",
    "fashion_scatter(fashion_tsne, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.unique(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "yhat=model([graphs[1]])\n",
    "make_dot(yhat, params=dict(list(model.named_parameters()))).render(\"gin_torchviz\", format=\"png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transforms = [ hl.transforms.Prune('Constant') ] # Removes Constant nodes from graph.\n",
    "\n",
    "graph = hl.build_graph(model, [graphs[1]], transforms=transforms)\n",
    "graph.theme = hl.graph.THEMES['blue'].copy()\n",
    "graph.save('rnn_hiddenlayer', format='png')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}