{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparative experiments over GraphRNN, GRAN and GraphOpt\n",
    "Ousmane TOUAT\n",
    "\n",
    "## Purpose\n",
    "Investigating on those deep graph generators methods over small-words graph, in order to design a capable RL-based generator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "### Libraries import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#Include local libraries\n",
    "import sys,os\n",
    "from synthethicDataset.generate_graphs import *\n",
    "from baselineModels.GraphRNN.train import *\n",
    "from baselineModels.GraphRNN.model import *\n",
    "from baselineModels.GraphRNN.data import *\n",
    "from experiment_config import *\n",
    "from time import strftime,gmtime\n",
    "import scipy.misc\n",
    "from tensorboard_logger import configure, log_value\n",
    "from random import shuffle\n",
    "import random\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing GraphRNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 0\n",
      "File name prefix GraphRNN_erdos_4_128_\n",
      "graph_validate_len 25.0\n",
      "graph_test_len 25.0\n",
      "total graph num: 200, training set: 160\n",
      "max number node: 25\n",
      "max/min number edge: 45; 15\n",
      "max previous node: 20\n",
      "train and test graphs saved at:  ./baselineModels/GraphRNN/graphs/GraphRNN_erdos_4_128_test_0.dat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ousmanetouat/Documents/Projets Python/graphRL/baselineModels/GraphRNN/model.py:44: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(param,gain=nn.init.calculate_gain('sigmoid'))\n",
      "/home/ousmanetouat/Documents/Projets Python/graphRL/baselineModels/GraphRNN/model.py:42: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(param, 0.25)\n",
      "/home/ousmanetouat/Documents/Projets Python/graphRL/baselineModels/GraphRNN/model.py:47: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  m.weight.data = init.xavier_uniform(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
      "/home/ousmanetouat/anaconda3/envs/graphRL/lib/python3.7/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/100, train loss: 0.087802, graph type: erdos, num_layer: 4, hidden: 128\n",
      "test done, graphs saved\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-9ed519c02fc5>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m \u001B[0;31m### start training\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 84\u001B[0;31m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnode_level_rnn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0medge_level_rnn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Documents/Projets Python/graphRL/baselineModels/GraphRNN/train.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(args, dataset_train, rnn, output)\u001B[0m\n\u001B[1;32m     44\u001B[0m         train_rnn_epoch(epoch, args, rnn, output, dataset_train,\n\u001B[1;32m     45\u001B[0m                         \u001B[0moptimizer_rnn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer_output\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 46\u001B[0;31m                         scheduler_rnn, scheduler_output)\n\u001B[0m\u001B[1;32m     47\u001B[0m         \u001B[0mtime_end\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m         \u001B[0mtime_all\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mepoch\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime_end\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mtime_start\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Projets Python/graphRL/baselineModels/GraphRNN/train.py\u001B[0m in \u001B[0;36mtrain_rnn_epoch\u001B[0;34m(epoch, args, rnn, output, data_loader, optimizer_rnn, optimizer_output, scheduler_rnn, scheduler_output)\u001B[0m\n\u001B[1;32m     77\u001B[0m     \u001B[0mloss_sum\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     78\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mbatch_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_loader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 79\u001B[0;31m         \u001B[0mrnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     80\u001B[0m         \u001B[0moutput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     81\u001B[0m         \u001B[0mx_unsorted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'x'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# All necessary arguments are defined in args.py\n",
    "args = Args()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(args.device)\n",
    "print('CUDA', args.device)\n",
    "print('File name prefix', args.fname)\n",
    "# check if necessary directories exist\n",
    "if not os.path.isdir(args.model_save_path):\n",
    "    os.makedirs(args.model_save_path)\n",
    "if not os.path.isdir(args.graph_save_path):\n",
    "    os.makedirs(args.graph_save_path)\n",
    "if not os.path.isdir(args.figure_save_path):\n",
    "    os.makedirs(args.figure_save_path)\n",
    "if not os.path.isdir(args.timing_save_path):\n",
    "    os.makedirs(args.timing_save_path)\n",
    "if not os.path.isdir(args.figure_prediction_save_path):\n",
    "    os.makedirs(args.figure_prediction_save_path)\n",
    "if not os.path.isdir(args.nll_save_path):\n",
    "    os.makedirs(args.nll_save_path)\n",
    "\n",
    "time = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "# logging.basicConfig(filename='logs/train' + time + '.log', level=logging.DEBUG)\n",
    "if args.clean_tensorboard:\n",
    "    if os.path.isdir(args.dir_input+\"/tensorboard\"):\n",
    "        shutil.rmtree(\"tensorboard\")\n",
    "configure(args.dir_input+\"/tensorboard/run\" + time, flush_secs=5)\n",
    "\n",
    "graphs = generate(args)\n",
    "\n",
    "# split datasets\n",
    "random.seed(123)\n",
    "shuffle(graphs)\n",
    "graphs_len = len(graphs)\n",
    "graphs_test = graphs[int(0.8 * graphs_len):]\n",
    "graphs_train = graphs[0:int(0.8 * graphs_len)]\n",
    "graphs_validate = graphs[0:int(0.2 * graphs_len)]\n",
    "\n",
    "graph_validate_len = 0\n",
    "for graph in graphs_validate:\n",
    "    graph_validate_len += graph.number_of_nodes()\n",
    "graph_validate_len /= len(graphs_validate)\n",
    "print('graph_validate_len', graph_validate_len)\n",
    "\n",
    "graph_test_len = 0\n",
    "for graph in graphs_test:\n",
    "    graph_test_len += graph.number_of_nodes()\n",
    "graph_test_len /= len(graphs_test)\n",
    "print('graph_test_len', graph_test_len)\n",
    "\n",
    "args.max_num_node = max([graphs[i].number_of_nodes() for i in range(len(graphs))])\n",
    "max_num_edge = max([graphs[i].number_of_edges() for i in range(len(graphs))])\n",
    "min_num_edge = min([graphs[i].number_of_edges() for i in range(len(graphs))])\n",
    "\n",
    "# args.max_num_node = 2000\n",
    "# show graphs statistics\n",
    "print('total graph num: {}, training set: {}'.format(len(graphs), len(graphs_train)))\n",
    "print('max number node: {}'.format(args.max_num_node))\n",
    "print('max/min number edge: {}; {}'.format(max_num_edge, min_num_edge))\n",
    "print('max previous node: {}'.format(args.max_prev_node))\n",
    "\n",
    "# save ground truth graphs\n",
    "## To get train and test set, after loading you need to manually slice\n",
    "save_graph_list(graphs, args.graph_save_path + args.fname_train + '0.dat')\n",
    "save_graph_list(graphs, args.graph_save_path + args.fname_test + '0.dat')\n",
    "print('train and test graphs saved at: ', args.graph_save_path + args.fname_test + '0.dat')\n",
    "\n",
    "### dataset initialization\n",
    "dataset = Graph_to_sequence(graphs_train, max_prev_node=args.max_prev_node,\n",
    "                                         max_num_node=args.max_num_node)\n",
    "sample_strategy = torch.utils.data.sampler.WeightedRandomSampler([1.0 / len(dataset) for i in range(len(dataset))],\n",
    "                                                                 num_samples=args.batch_size * args.batch_ratio,\n",
    "                                                                 replacement=True)\n",
    "dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, num_workers=args.num_workers,\n",
    "                                             sampler=sample_strategy)\n",
    "\n",
    "### model initialization\n",
    "node_level_rnn = RNN(input_size=args.max_prev_node, embedding_size=args.embedding_size_rnn,\n",
    "                        hidden_size=args.hidden_size_rnn, num_layers=args.num_layers, has_input=True,\n",
    "                        has_output=True, output_size=args.hidden_size_rnn_output).cuda()\n",
    "edge_level_rnn = RNN(input_size=1, embedding_size=args.embedding_size_rnn_output,\n",
    "                           hidden_size=args.hidden_size_rnn_output, num_layers=args.num_layers, has_input=True,\n",
    "                           has_output=True, output_size=1).cuda()\n",
    "\n",
    "### start training\n",
    "train(args, dataset_loader, node_level_rnn, edge_level_rnn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}