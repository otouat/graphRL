{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Comparative experiments over GraphRNN, GRAN and GraphOpt\n",
    "Ousmane TOUAT\n",
    "\n",
    "## Purpose\n",
    "Investigating on those deep graph generators methods over small-words graph, in order to design a capable RL-based generator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "### Libraries import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#Include local libraries\n",
    "import sys, os\n",
    "from synthethicDataset.generate_graphs import *\n",
    "from baselineModels.GraphRNN.train import *\n",
    "from baselineModels.GraphRNN.model import *\n",
    "from baselineModels.GraphRNN.data import *\n",
    "from config.experiment_config import *\n",
    "from time import strftime, gmtime\n",
    "import scipy.misc\n",
    "from tensorboard_logger import configure, log_value\n",
    "from random import shuffle\n",
    "import random\n",
    "import pickle\n",
    "import shutil"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset initialization and creation\n",
    "We will generate graphs using stocasthic model such as Erdos Renyi or Barabasi Albert"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 0\n",
      "File name prefix GraphRNN_MLP_erdos_4_128_\n",
      "graph_validate_len 143.45\n",
      "graph_test_len 150.5\n",
      "total graph num: 100, training set: 80\n",
      "max number node: 199\n",
      "max/min number edge: 2001; 475\n",
      "max previous node: None\n",
      "train and test graphs saved at:  ./baselineModels/GraphRNN/ModelData/graphs/GraphRNN_MLP_erdos_4_128_test_0.dat\n",
      "calculating max previous node, total iteration: 20000\n",
      "iter 0 times\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-674fa769211c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[1;31m### dataset initialization\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m dataset = Graph_to_sequence(graphs_train, max_prev_node=args.max_prev_node,\n\u001B[1;32m---> 67\u001B[1;33m                             max_num_node=args.max_num_node)\n\u001B[0m\u001B[0;32m     68\u001B[0m sample_strategy = torch.utils.data.sampler.WeightedRandomSampler([1.0 / len(dataset) for i in range(len(dataset))],\n\u001B[0;32m     69\u001B[0m                                                                  \u001B[0mnum_samples\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatch_size\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatch_ratio\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\graphRL\\baselineModels\\GraphRNN\\data.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, G_list, max_num_node, max_prev_node, iteration)\u001B[0m\n\u001B[0;32m     22\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mmax_prev_node\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m             \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'calculating max previous node, total iteration: {}'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miteration\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax_prev_node\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcalc_max_prev_node\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miter\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0miteration\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m             \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'max previous node: {}'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax_prev_node\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\graphRL\\baselineModels\\GraphRNN\\data.py\u001B[0m in \u001B[0;36mcalc_max_prev_node\u001B[1;34m(self, iter, topk)\u001B[0m\n\u001B[0;32m     70\u001B[0m             \u001B[0madj_copy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0madj_copy\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mix_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_idx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_idx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m             \u001B[0madj_copy_matrix\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masmatrix\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0madj_copy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 72\u001B[1;33m             \u001B[0mG\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_numpy_matrix\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0madj_copy_matrix\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     73\u001B[0m             \u001B[1;31m# then do bfs in the permuted G\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m             \u001B[0mstart_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0madj_copy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda3\\envs\\graphRL\\lib\\site-packages\\networkx\\convert_matrix.py\u001B[0m in \u001B[0;36mfrom_numpy_matrix\u001B[1;34m(A, parallel_edges, create_using)\u001B[0m\n\u001B[0;32m    596\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mG\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_multigraph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mG\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_directed\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    597\u001B[0m         \u001B[0mtriples\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mu\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0md\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mu\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0md\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtriples\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mu\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 598\u001B[1;33m     \u001B[0mG\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_edges_from\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtriples\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    599\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mG\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    600\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda3\\envs\\graphRL\\lib\\site-packages\\networkx\\classes\\graph.py\u001B[0m in \u001B[0;36madd_edges_from\u001B[1;34m(self, ebunch_to_add, **attr)\u001B[0m\n\u001B[0;32m    977\u001B[0m             \u001B[0mdatadict\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mattr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    978\u001B[0m             \u001B[0mdatadict\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 979\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_adj\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mu\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdatadict\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    980\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_adj\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mu\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdatadict\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    981\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "args = Args()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(args.device)\n",
    "print('CUDA', args.device)\n",
    "print('File name prefix', args.fname)\n",
    "# check if necessary directories exist\n",
    "if not os.path.isdir(args.model_save_path):\n",
    "    os.makedirs(args.model_save_path)\n",
    "if not os.path.isdir(args.graph_save_path):\n",
    "    os.makedirs(args.graph_save_path)\n",
    "if not os.path.isdir(args.figure_save_path):\n",
    "    os.makedirs(args.figure_save_path)\n",
    "if not os.path.isdir(args.timing_save_path):\n",
    "    os.makedirs(args.timing_save_path)\n",
    "if not os.path.isdir(args.figure_prediction_save_path):\n",
    "    os.makedirs(args.figure_prediction_save_path)\n",
    "if not os.path.isdir(args.nll_save_path):\n",
    "    os.makedirs(args.nll_save_path)\n",
    "\n",
    "time = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "# logging.basicConfig(filename='logs/train' + time + '.log', level=logging.DEBUG)\n",
    "if args.clean_tensorboard:\n",
    "    if os.path.isdir(args.dir_input + \"tensorboard\"):\n",
    "        shutil.rmtree(args.dir_input + \"tensorboard\")\n",
    "configure(args.dir_input + \"/tensorboard/run\", flush_secs=5)\n",
    "\n",
    "graphs = generate(args)\n",
    "\n",
    "# split datasets\n",
    "random.seed(123)\n",
    "shuffle(graphs)\n",
    "graphs_len = len(graphs)\n",
    "graphs_test = graphs[int(0.8 * graphs_len):]\n",
    "graphs_train = graphs[0:int(0.8 * graphs_len)]\n",
    "graphs_validate = graphs[0:int(0.2 * graphs_len)]\n",
    "\n",
    "graph_validate_len = 0\n",
    "for graph in graphs_validate:\n",
    "    graph_validate_len += graph.number_of_nodes()\n",
    "graph_validate_len /= len(graphs_validate)\n",
    "print('graph_validate_len', graph_validate_len)\n",
    "\n",
    "graph_test_len = 0\n",
    "for graph in graphs_test:\n",
    "    graph_test_len += graph.number_of_nodes()\n",
    "graph_test_len /= len(graphs_test)\n",
    "print('graph_test_len', graph_test_len)\n",
    "\n",
    "args.max_num_node = max([graphs[i].number_of_nodes() for i in range(len(graphs))])\n",
    "max_num_edge = max([graphs[i].number_of_edges() for i in range(len(graphs))])\n",
    "min_num_edge = min([graphs[i].number_of_edges() for i in range(len(graphs))])\n",
    "\n",
    "# args.max_num_node = 2000\n",
    "# show graphs statistics\n",
    "print('total graph num: {}, training set: {}'.format(len(graphs), len(graphs_train)))\n",
    "print('max number node: {}'.format(args.max_num_node))\n",
    "print('max/min number edge: {}; {}'.format(max_num_edge, min_num_edge))\n",
    "print('max previous node: {}'.format(args.max_prev_node))\n",
    "\n",
    "# save ground truth graphs\n",
    "## To get train and test set, after loading you need to manually slice\n",
    "save_graph_list(graphs, args.graph_save_path + args.fname_train + '0.dat')\n",
    "save_graph_list(graphs, args.graph_save_path + args.fname_test + '0.dat')\n",
    "print('train and test graphs saved at: ', args.graph_save_path + args.fname_test + '0.dat')\n",
    "\n",
    "### dataset initialization\n",
    "dataset = Graph_to_sequence(graphs_train, max_prev_node=args.max_prev_node,\n",
    "                            max_num_node=args.max_num_node)\n",
    "sample_strategy = torch.utils.data.sampler.WeightedRandomSampler([1.0 / len(dataset) for i in range(len(dataset))],\n",
    "                                                                 num_samples=args.batch_size * args.batch_ratio,\n",
    "                                                                 replacement=True)\n",
    "dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, num_workers=args.num_workers,\n",
    "                                             sampler=sample_strategy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialisation of the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# All necessary arguments are defined in args.py\n",
    "args.max_prev_node = dataset.max_prev_node\n",
    "\n",
    "### model initialization\n",
    "if 'GraphRNN_MLP' in args.note:\n",
    "        node_level_rnn = RNN(input_size=args.max_prev_node, embedding_size=args.embedding_size_rnn,\n",
    "                        hidden_size=args.hidden_size_rnn, num_layers=args.num_layers, has_input=True,\n",
    "                        has_output=False).cuda()\n",
    "        edge_level_rnn = MLP_plain(h_size=args.hidden_size_rnn, embedding_size=args.embedding_size_output, y_size=args.max_prev_node).cuda()\n",
    "else:\n",
    "    node_level_rnn = RNN(input_size=args.max_prev_node, embedding_size=args.embedding_size_rnn,\n",
    "                         hidden_size=args.hidden_size_rnn, num_layers=args.num_layers, has_input=True,\n",
    "                         has_output=True, output_size=args.hidden_size_rnn_output).cuda()\n",
    "    edge_level_rnn = RNN(input_size=1, embedding_size=args.embedding_size_rnn_output,\n",
    "                         hidden_size=args.hidden_size_rnn_output, num_layers=args.num_layers, has_input=True,\n",
    "                         has_output=True, output_size=1).cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### start training\n",
    "train(args, dataset_loader, node_level_rnn, edge_level_rnn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generated_graphs = test_rnn_epoch(0, args, node_level_rnn, edge_level_rnn, 50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nx.draw(generated_graphs[5])\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}